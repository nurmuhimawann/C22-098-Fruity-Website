# -*- coding: utf-8 -*-
"""Experiment_CNN_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12EcIyw8aaQ-wtyafBxULIybCleCb-_Lb
"""

# import library
import os
import shutil
import random
import zipfile
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from google.colab import files

# kaggle.json downloaded >> https://drive.google.com/file/d/1x5RMQ3yp049uZIxtIqNg3PwFqOqAAcu3/view?usp=share_link
! pip install gdown
! gdown 1x5RMQ3yp049uZIxtIqNg3PwFqOqAAcu3
! ls

# Connect the Kaggle API client
! pip install -q kaggle

# move API client in ~/.kaggle
! mkdir ~/.kaggle
! cp "/content/kaggle.json" ~/.kaggle/kaggle.json
! chmod 600 ~/.kaggle/kaggle.json

# dataset downloaded >> https://www.kaggle.com/datasets/sriramr/fruits-fresh-and-rotten-for-classification
! kaggle datasets download sriramr/fruits-fresh-and-rotten-for-classification

# extract the zip file
local_zip = "/content/fruits-fresh-and-rotten-for-classification.zip"
zip_ref = zipfile.ZipFile(local_zip, "r")
zip_ref.extractall("/content")
zip_ref.close()

# remove unused files
shutil.rmtree("/content/dataset/dataset")
os.remove("fruits-fresh-and-rotten-for-classification.zip")

# show sample files
image_path = os.listdir("/content/dataset/train/freshapples")
fruit_sample = random.choice(image_path)
img = tf.keras.preprocessing.image.load_img("/content/dataset/train/freshapples/" + fruit_sample)
plt.imshow(img)
print("size of image: {}".format(img.size))

# directory specification
base_dir = r"/content/dataset"

train_dir = os.path.join(base_dir, "train")
validation_dir = os.path.join(base_dir, "test")

# define label variables
labels = os.listdir(validation_dir)

# data augmentation
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)
validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)

# process image
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=15,
    class_mode='categorical')
    
validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=15,
    class_mode='categorical',)

# create sequential models
model = tf.keras.models.Sequential([
    # tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    # tf.keras.layers.MaxPooling2D(2, 2),
    # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    # tf.keras.layers.MaxPooling2D(2,2),
    # tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    # tf.keras.layers.MaxPooling2D(2,2),
    # tf.keras.layers.Dropout(0.25),
    # tf.keras.layers.Flatten(),
    # tf.keras.layers.Dense(256, activation='relu'),
    # tf.keras.layers.Dense(len(labels), activation='softmax')

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(len(labels), activation='softmax')
])

# optimizer and crossentropy loss
model.compile(loss='categorical_crossentropy',
              optimizer='adamax',
              metrics=['accuracy'])

# summary
model.summary()

# callbacks & checkpoint functions
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if logs.get('accuracy') >= 0.99 and logs.get('val_accuracy') >= 0.99:
      print("\nTarget reached 99%. Stop Training")
      self.model.stop_training = True

callbacks = myCallback()

checkpoint_filepath = 'model/model_weights.{epoch:02d}-{val_loss:.3f}.h5'
checkpoint_save = tf.keras.callbacks.ModelCheckpoint(
                    filepath=checkpoint_filepath,
                    monitor='val_accuracy',
                    mode='max',
                    save_best_only=True)

# models training
history=model.fit(
      train_generator,
      epochs=30,
      validation_data=validation_generator,
      verbose=1,
      callbacks=[callbacks, checkpoint_save])

# plotting accuracy metrics
plt.figure(figsize=(9,6))

plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')

acc = plt.plot(history.history['accuracy'], color='blue')
val_acc = plt.plot(history.history['val_accuracy'], color='red')

plt.legend(['Train Accuracy', 'Validation Accuracy'], loc='lower right')

plt.show()

# plotting loss metrics
plt.figure(figsize=(9,6))

plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')

loss = plt.plot(history.history['loss'], color='red')
val_loss = plt.plot(history.history['val_loss'], color='blue')

plt.legend(['Loss', 'Validation Loss'], loc='upper right')

plt.show()

# model conversion
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

model.save("model.h5")

# Commented out IPython magic to ensure Python compatibility.
# predict image
# %matplotlib inline
uploaded = files.upload()

for fn in uploaded.keys():
  path = fn
  img = tf.keras.utils.load_img(path, target_size=(150, 150))
  imgplot = plt.imshow(img)
  x = tf.keras.utils.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  arr = model.predict(images, batch_size=10)
  if arr[0][0]==1:
    labels='Fresh Apple'
  elif arr[0][1]==1:
    labels='Fresh Banana'
  elif arr[0][2]==1:
    labels='Fresh Oranges'
  elif arr[0][3]==1:
    labels='Rotten Apple'
  elif arr[0][4]==1:
    labels='Rotten Banana'
  elif arr[0][5]==1:
    labels='Rotten Oranges'
print('{} is a {}'.format(fn,labels))